<test_automation_report><header><title>🚀 Python Project Test Automation Report</title><generated>2025-09-14 06:03:36</generated><model_name>llama-3.3-70b-versatile</model_name><execution_time_seconds>0.452642</execution_time_seconds><status>FAILED</status></header><syntax_validation><validation test="ci_pr_test_runner.py">True</validation><validation test="tests_pr/pr_generated_tests.py">True</validation></syntax_validation><analyzed_functions><count>32</count><function><name>to_dict</name><file_path>ci_pr_test_runner.py</file_path><line_start>69</line_start><line_end>78</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>TestCaseResult</class_name><code_snippet>    def to_dict(self) -&gt; Dict[str, Any]:
        """Convert to dictionary for JSON serialization"""
        return {
            "name": self.name,
            "status": self.status,
            "exec...</code_snippet></function><function><name>__init__</name><file_path>ci_pr_test_runner.py</file_path><line_start>98</line_start><line_end>100</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>CodeAnalyzer</class_name><code_snippet>    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.builtin_types = {'int', 'str', 'float', 'bool', 'list', 'dict', 'tuple', 'set', 'bytes', 'None'}</code_snippet></function><function><name>extract_type_info</name><file_path>ci_pr_test_runner.py</file_path><line_start>102</line_start><line_end>121</line_end><is_method>True</is_method><complexity_score>6</complexity_score><class_name>CodeAnalyzer</class_name><code_snippet>    def extract_type_info(self, node: ast.FunctionDef) -&gt; TypeInfo:
        """Extract comprehensive type information from function definition"""
        type_info = TypeInfo()
        
        # Extr...</code_snippet></function><function><name>extract_imports_from_file</name><file_path>ci_pr_test_runner.py</file_path><line_start>123</line_start><line_end>148</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>CodeAnalyzer</class_name><code_snippet>    def extract_imports_from_file(self, file_path: Path) -&gt; ImportInfo:
        """Extract all imports from a Python file"""
        import_info = ImportInfo()
        
        try:
            with o...</code_snippet></function><function><name>calculate_complexity_score</name><file_path>ci_pr_test_runner.py</file_path><line_start>150</line_start><line_end>162</line_end><is_method>True</is_method><complexity_score>5</complexity_score><class_name>CodeAnalyzer</class_name><code_snippet>    def calculate_complexity_score(self, node: ast.FunctionDef) -&gt; int:
        """Calculate a simple complexity score for the function"""
        score = 1
        
        for child in ast.walk(node...</code_snippet></function><function><name>__init__</name><file_path>ci_pr_test_runner.py</file_path><line_start>167</line_start><line_end>168</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>TestValidator</class_name><code_snippet>    def __init__(self, project_root: Path):
        self.project_root = project_root</code_snippet></function><function><name>validate_syntax</name><file_path>ci_pr_test_runner.py</file_path><line_start>170</line_start><line_end>187</line_end><is_method>True</is_method><complexity_score>4</complexity_score><class_name>TestValidator</class_name><code_snippet>    def validate_syntax(self, test_code: str) -&gt; Tuple[bool, List[str]]:
        """Validate Python syntax of generated test code"""
        errors = []
        
        try:
            # First, try ...</code_snippet></function><function><name>validate_imports</name><file_path>ci_pr_test_runner.py</file_path><line_start>189</line_start><line_end>211</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>TestValidator</class_name><code_snippet>    def validate_imports(self, test_code: str, available_modules: Set[str]) -&gt; Tuple[bool, List[str]]:
        """Validate that all imports in test code are available"""
        errors = []
        
 ...</code_snippet></function><function><name>__init__</name><file_path>ci_pr_test_runner.py</file_path><line_start>217</line_start><line_end>233</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def __init__(self):
        self.project_root = Path(os.getcwd())
        sys.path.insert(0, str(self.project_root))
        
        self.test_dir = self.project_root / DEFAULT_TEST_DIR
        s...</code_snippet></function><function><name>_log</name><file_path>ci_pr_test_runner.py</file_path><line_start>235</line_start><line_end>240</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _log(self, message: str, level: str = "INFO"):
        """Add a log entry with timestamp"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}]...</code_snippet></function><function><name>_get_changed_files</name><file_path>ci_pr_test_runner.py</file_path><line_start>242</line_start><line_end>251</line_end><is_method>True</is_method><complexity_score>2</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _get_changed_files(self) -&gt; List[str]:
        """Gets changed files from the GITHUB_ENV variable."""
        changed_files_str = os.environ.get("CHANGED_FILES", "")
        if not changed_fil...</code_snippet></function><function><name>_extract_functions_from_file</name><file_path>ci_pr_test_runner.py</file_path><line_start>253</line_start><line_end>322</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _extract_functions_from_file(self, file_path: Path) -&gt; List[FunctionInfo]:
        """Enhanced function extraction with detailed analysis"""
        functions = []
        
        try:
      ...</code_snippet></function><function><name>_build_comprehensive_prompt</name><file_path>ci_pr_test_runner.py</file_path><line_start>324</line_start><line_end>479</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _build_comprehensive_prompt(self, functions: List[FunctionInfo]) -&gt; str:
        """Build a comprehensive, structured prompt for better test generation"""
        
        # Analyze all functi...</code_snippet></function><function><name>_invoke_llm_for_generation</name><file_path>ci_pr_test_runner.py</file_path><line_start>481</line_start><line_end>532</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _invoke_llm_for_generation(self, prompt: str, max_retries: int = 3) -&gt; str:
        """Enhanced LLM invocation with retry logic and validation"""
        
        for attempt in range(max_retr...</code_snippet></function><function><name>_generate_test_suite</name><file_path>ci_pr_test_runner.py</file_path><line_start>534</line_start><line_end>555</line_end><is_method>True</is_method><complexity_score>4</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _generate_test_suite(self, functions: List[FunctionInfo]) -&gt; str:
        """Generate test suite with enhanced validation"""
        if not functions:
            return ""

        # Build co...</code_snippet></function><function><name>_fix_common_syntax_issues</name><file_path>ci_pr_test_runner.py</file_path><line_start>557</line_start><line_end>578</line_end><is_method>True</is_method><complexity_score>9</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _fix_common_syntax_issues(self, code: str) -&gt; str:
        """Fix common syntax issues in generated code"""
        lines = code.split('\n')
        fixed_lines = []
        
        for line ...</code_snippet></function><function><name>_format_python_code</name><file_path>ci_pr_test_runner.py</file_path><line_start>580</line_start><line_end>608</line_end><is_method>True</is_method><complexity_score>6</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _format_python_code(self, file_path: Path):
        """Enhanced code formatting with validation"""
        try:
            # First, validate the file can be parsed
            with open(file_...</code_snippet></function><function><name>_parse_test_output</name><file_path>ci_pr_test_runner.py</file_path><line_start>610</line_start><line_end>694</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _parse_test_output(self, test_output: str, test_stderr: str) -&gt; List[TestCaseResult]:
        """Parse unittest output to extract individual test case results"""
        test_cases = []
      ...</code_snippet></function><function><name>_extract_test_methods_from_file</name><file_path>ci_pr_test_runner.py</file_path><line_start>696</line_start><line_end>718</line_end><is_method>True</is_method><complexity_score>7</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _extract_test_methods_from_file(self) -&gt; List[TestCaseResult]:
        """Extract test method names from the generated test file"""
        test_cases = []
        test_file_path = self.test_d...</code_snippet></function><function><name>_execute_tests</name><file_path>ci_pr_test_runner.py</file_path><line_start>720</line_start><line_end>823</line_end><is_method>True</is_method><complexity_score>9</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _execute_tests(self, test_file_path: Path, changed_files: List[str]) -&gt; Dict[str, Any]:
        """Enhanced test execution with better error handling"""
        self._log(f"🧪 Executing tests f...</code_snippet></function><function><name>_parse_coverage_metrics</name><file_path>ci_pr_test_runner.py</file_path><line_start>825</line_start><line_end>850</line_end><is_method>True</is_method><complexity_score>7</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _parse_coverage_metrics(self, coverage_output: str) -&gt; Dict[str, str]:
        """Enhanced coverage metrics parsing"""
        metrics = {}
        if not coverage_output:
            return m...</code_snippet></function><function><name>_generate_json_report</name><file_path>ci_pr_test_runner.py</file_path><line_start>852</line_start><line_end>883</line_end><is_method>True</is_method><complexity_score>2</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _generate_json_report(self, report: TestReport) -&gt; str:
        """Enhanced JSON report generation"""
        report_dict = {
            "title": "🚀 Python Project Test Automation Report",
  ...</code_snippet></function><function><name>_generate_xml_report</name><file_path>ci_pr_test_runner.py</file_path><line_start>885</line_start><line_end>957</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _generate_xml_report(self, report: TestReport) -&gt; str:
        """Enhanced XML report generation"""
        root = ET.Element("test_automation_report")
        
        # Header with additiona...</code_snippet></function><function><name>_generate_text_report</name><file_path>ci_pr_test_runner.py</file_path><line_start>959</line_start><line_end>1065</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _generate_text_report(self, report: TestReport) -&gt; str:
        """Enhanced human-readable text format report"""
        lines = [
            "🚀 Python Project Test Automation Report",
      ...</code_snippet></function><function><name>_save_reports</name><file_path>ci_pr_test_runner.py</file_path><line_start>1067</line_start><line_end>1091</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _save_reports(self, report: TestReport):
        """Save enhanced reports in multiple formats"""
        timestamp_str = report.timestamp.replace(":", "-").replace(" ", "_")
        base_filen...</code_snippet></function><function><name>run</name><file_path>ci_pr_test_runner.py</file_path><line_start>1093</line_start><line_end>1270</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def run(self):
        """Enhanced main runner with comprehensive validation"""
        self._log("🚀 Starting Enhanced Python Project Test Automation", "INFO")
        
        changed_files = sel...</code_snippet></function><function><name>setUp</name><file_path>tests_pr/pr_generated_tests.py</file_path><line_start>9</line_start><line_end>10</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>TestGeneratedCode</class_name><code_snippet>    def setUp(self):
        pass</code_snippet></function><function><name>test_sum_three_numbers_normal_case</name><file_path>tests_pr/pr_generated_tests.py</file_path><line_start>12</line_start><line_end>14</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>TestGeneratedCode</class_name><code_snippet>    def test_sum_three_numbers_normal_case(self):
        self.assertEqual(sum_three_numbers(1, 2, 3), 6)
        self.assertEqual(sum_three_numbers(1.5, 2.5, 3.5), 7.5)</code_snippet></function><function><name>test_sum_three_numbers_edge_cases</name><file_path>tests_pr/pr_generated_tests.py</file_path><line_start>16</line_start><line_end>19</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>TestGeneratedCode</class_name><code_snippet>    def test_sum_three_numbers_edge_cases(self):
        self.assertEqual(sum_three_numbers(0, 0, 0), 0)
        self.assertEqual(sum_three_numbers(-1, -2, -3), -6)
        self.assertEqual(sum_three_...</code_snippet></function><function><name>test_sum_three_numbers_type_validation</name><file_path>tests_pr/pr_generated_tests.py</file_path><line_start>21</line_start><line_end>23</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>TestGeneratedCode</class_name><code_snippet>    def test_sum_three_numbers_type_validation(self):
        self.assertIsInstance(sum_three_numbers(1, 2, 3), int)
        self.assertIsInstance(sum_three_numbers(1.5, 2.5, 3.5), float)</code_snippet></function><function><name>test_sum_three_numbers_error_cases</name><file_path>tests_pr/pr_generated_tests.py</file_path><line_start>25</line_start><line_end>31</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>TestGeneratedCode</class_name><code_snippet>    def test_sum_three_numbers_error_cases(self):
        with self.assertRaises(TypeError):
            sum_three_numbers('a', 2, 3)
        with self.assertRaises(TypeError):
            sum_three_n...</code_snippet></function><function><name>test_sum_three_numbers_none_values</name><file_path>tests_pr/pr_generated_tests.py</file_path><line_start>33</line_start><line_end>39</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>TestGeneratedCode</class_name><code_snippet>    def test_sum_three_numbers_none_values(self):
        with self.assertRaises(TypeError):
            sum_three_numbers(None, 2, 3)
        with self.assertRaises(TypeError):
            sum_three_...</code_snippet></function></analyzed_functions><test_results><status>failure</status><output>Failed to generate test cases</output></test_results><test_cases /><coverage_metrics /><execution_logs><count>19</count><log>[2025-09-14 06:03:35] [INFO] 🚀 Starting Enhanced Python Project Test Automation</log><log>[2025-09-14 06:03:35] [INFO] 📁 Detected 3 changed files: ci_pr_test_runner.py, reports/run_summary.txt, tests_pr/pr_generated_tests.py</log><log>[2025-09-14 06:03:35] [INFO] 🔍 Analyzing changed file: ci_pr_test_runner.py</log><log>[2025-09-14 06:03:35] [INFO] ✅ Found 26 functions/methods in ci_pr_test_runner.py</log><log>[2025-09-14 06:03:35] [INFO] 🔍 Analyzing changed file: tests_pr/pr_generated_tests.py</log><log>[2025-09-14 06:03:35] [INFO] ✅ Found 6 functions/methods in tests_pr/pr_generated_tests.py</log><log>[2025-09-14 06:03:35] [INFO] 📊 Analysis Summary:</log><log>[2025-09-14 06:03:35] [INFO]    Total Functions/Methods: 32</log><log>[2025-09-14 06:03:35] [INFO]    Functions: 0, Methods: 32</log><log>[2025-09-14 06:03:35] [INFO]    Average Complexity: 5.1/10</log><log>[2025-09-14 06:03:35] [INFO] 🧠 Generating comprehensive test cases using llama-3.3-70b-versatile...</log><log>[2025-09-14 06:03:35] [INFO] 🤖 Generating test code (attempt 1/3)...</log><log>[2025-09-14 06:03:35] [ERROR] ❌ Error in LLM generation (attempt 1): Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01k4vv26wrfy0a45edrkbynbm1` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Requested 15982, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}</log><log>[2025-09-14 06:03:35] [INFO] 🤖 Generating test code (attempt 2/3)...</log><log>[2025-09-14 06:03:36] [ERROR] ❌ Error in LLM generation (attempt 2): Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01k4vv26wrfy0a45edrkbynbm1` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Requested 15982, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}</log><log>[2025-09-14 06:03:36] [INFO] 🤖 Generating test code (attempt 3/3)...</log><log>[2025-09-14 06:03:36] [ERROR] ❌ Error in LLM generation (attempt 3): Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01k4vv26wrfy0a45edrkbynbm1` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Requested 15982, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}</log><log>[2025-09-14 06:03:36] [ERROR] ❌ Failed to generate test cases. Aborting.</log><log>[2025-09-14 06:03:36] [INFO] 📄 JSON report saved: /home/runner/work/check-python-tests/check-python-tests/reports/test_automation_report_2025-09-14_06-03-36.json</log></execution_logs></test_automation_report>