<test_automation_report><header><title>🚀 Python Project Test Automation Report</title><generated>2025-09-14 06:13:48</generated><model_name>llama-3.3-70b-versatile</model_name><execution_time_seconds>0.516231</execution_time_seconds><status>FAILED</status></header><syntax_validation><validation test="ci_pr_test_runner.py">True</validation><validation test="utils.py">True</validation></syntax_validation><analyzed_functions><count>27</count><function><name>to_dict</name><file_path>ci_pr_test_runner.py</file_path><line_start>70</line_start><line_end>79</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>TestCaseResult</class_name><code_snippet>    def to_dict(self) -&gt; Dict[str, Any]:
        """Convert to dictionary for JSON serialization"""
        return {
            "name": self.name,
            "status": self.status,
            "exec...</code_snippet></function><function><name>__init__</name><file_path>ci_pr_test_runner.py</file_path><line_start>99</line_start><line_end>101</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>CodeAnalyzer</class_name><code_snippet>    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.builtin_types = {'int', 'str', 'float', 'bool', 'list', 'dict', 'tuple', 'set', 'bytes', 'None'}</code_snippet></function><function><name>extract_type_info</name><file_path>ci_pr_test_runner.py</file_path><line_start>103</line_start><line_end>122</line_end><is_method>True</is_method><complexity_score>6</complexity_score><class_name>CodeAnalyzer</class_name><code_snippet>    def extract_type_info(self, node: ast.FunctionDef) -&gt; TypeInfo:
        """Extract comprehensive type information from function definition"""
        type_info = TypeInfo()
        
        # Extr...</code_snippet></function><function><name>extract_imports_from_file</name><file_path>ci_pr_test_runner.py</file_path><line_start>124</line_start><line_end>149</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>CodeAnalyzer</class_name><code_snippet>    def extract_imports_from_file(self, file_path: Path) -&gt; ImportInfo:
        """Extract all imports from a Python file"""
        import_info = ImportInfo()
        
        try:
            with o...</code_snippet></function><function><name>calculate_complexity_score</name><file_path>ci_pr_test_runner.py</file_path><line_start>151</line_start><line_end>163</line_end><is_method>True</is_method><complexity_score>5</complexity_score><class_name>CodeAnalyzer</class_name><code_snippet>    def calculate_complexity_score(self, node: ast.FunctionDef) -&gt; int:
        """Calculate a simple complexity score for the function"""
        score = 1
        
        for child in ast.walk(node...</code_snippet></function><function><name>__init__</name><file_path>ci_pr_test_runner.py</file_path><line_start>168</line_start><line_end>169</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>TestValidator</class_name><code_snippet>    def __init__(self, project_root: Path):
        self.project_root = project_root</code_snippet></function><function><name>validate_syntax</name><file_path>ci_pr_test_runner.py</file_path><line_start>171</line_start><line_end>188</line_end><is_method>True</is_method><complexity_score>4</complexity_score><class_name>TestValidator</class_name><code_snippet>    def validate_syntax(self, test_code: str) -&gt; Tuple[bool, List[str]]:
        """Validate Python syntax of generated test code"""
        errors = []
        
        try:
            # First, try ...</code_snippet></function><function><name>validate_imports</name><file_path>ci_pr_test_runner.py</file_path><line_start>190</line_start><line_end>212</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>TestValidator</class_name><code_snippet>    def validate_imports(self, test_code: str, available_modules: Set[str]) -&gt; Tuple[bool, List[str]]:
        """Validate that all imports in test code are available"""
        errors = []
        
 ...</code_snippet></function><function><name>__init__</name><file_path>ci_pr_test_runner.py</file_path><line_start>218</line_start><line_end>234</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def __init__(self):
        self.project_root = Path(os.getcwd())
        sys.path.insert(0, str(self.project_root))
        
        self.test_dir = self.project_root / DEFAULT_TEST_DIR
        s...</code_snippet></function><function><name>_log</name><file_path>ci_pr_test_runner.py</file_path><line_start>236</line_start><line_end>241</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _log(self, message: str, level: str = "INFO"):
        """Add a log entry with timestamp"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}]...</code_snippet></function><function><name>_get_changed_files</name><file_path>ci_pr_test_runner.py</file_path><line_start>243</line_start><line_end>252</line_end><is_method>True</is_method><complexity_score>2</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _get_changed_files(self) -&gt; List[str]:
        """Gets changed files from the GITHUB_ENV variable."""
        changed_files_str = os.environ.get("CHANGED_FILES", "")
        if not changed_fil...</code_snippet></function><function><name>_extract_functions_from_file</name><file_path>ci_pr_test_runner.py</file_path><line_start>254</line_start><line_end>323</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _extract_functions_from_file(self, file_path: Path) -&gt; List[FunctionInfo]:
        """Enhanced function extraction with detailed analysis"""
        functions = []
        
        try:
      ...</code_snippet></function><function><name>_build_comprehensive_prompt</name><file_path>ci_pr_test_runner.py</file_path><line_start>325</line_start><line_end>480</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _build_comprehensive_prompt(self, functions: List[FunctionInfo]) -&gt; str:
        """Build a comprehensive, structured prompt for better test generation"""
        
        # Analyze all functi...</code_snippet></function><function><name>_invoke_llm_for_generation</name><file_path>ci_pr_test_runner.py</file_path><line_start>482</line_start><line_end>533</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _invoke_llm_for_generation(self, prompt: str, max_retries: int = 3) -&gt; str:
        """Enhanced LLM invocation with retry logic and validation"""
        
        for attempt in range(max_retr...</code_snippet></function><function><name>_generate_test_suite</name><file_path>ci_pr_test_runner.py</file_path><line_start>535</line_start><line_end>556</line_end><is_method>True</is_method><complexity_score>4</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _generate_test_suite(self, functions: List[FunctionInfo]) -&gt; str:
        """Generate test suite with enhanced validation"""
        if not functions:
            return ""

        # Build co...</code_snippet></function><function><name>_fix_common_syntax_issues</name><file_path>ci_pr_test_runner.py</file_path><line_start>558</line_start><line_end>579</line_end><is_method>True</is_method><complexity_score>9</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _fix_common_syntax_issues(self, code: str) -&gt; str:
        """Fix common syntax issues in generated code"""
        lines = code.split('\n')
        fixed_lines = []
        
        for line ...</code_snippet></function><function><name>_format_python_code</name><file_path>ci_pr_test_runner.py</file_path><line_start>581</line_start><line_end>609</line_end><is_method>True</is_method><complexity_score>6</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _format_python_code(self, file_path: Path):
        """Enhanced code formatting with validation"""
        try:
            # First, validate the file can be parsed
            with open(file_...</code_snippet></function><function><name>_parse_test_output</name><file_path>ci_pr_test_runner.py</file_path><line_start>611</line_start><line_end>695</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _parse_test_output(self, test_output: str, test_stderr: str) -&gt; List[TestCaseResult]:
        """Parse unittest output to extract individual test case results"""
        test_cases = []
      ...</code_snippet></function><function><name>_extract_test_methods_from_file</name><file_path>ci_pr_test_runner.py</file_path><line_start>697</line_start><line_end>719</line_end><is_method>True</is_method><complexity_score>7</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _extract_test_methods_from_file(self) -&gt; List[TestCaseResult]:
        """Extract test method names from the generated test file"""
        test_cases = []
        test_file_path = self.test_d...</code_snippet></function><function><name>_execute_tests</name><file_path>ci_pr_test_runner.py</file_path><line_start>721</line_start><line_end>824</line_end><is_method>True</is_method><complexity_score>9</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _execute_tests(self, test_file_path: Path, changed_files: List[str]) -&gt; Dict[str, Any]:
        """Enhanced test execution with better error handling"""
        self._log(f"🧪 Executing tests f...</code_snippet></function><function><name>_parse_coverage_metrics</name><file_path>ci_pr_test_runner.py</file_path><line_start>826</line_start><line_end>851</line_end><is_method>True</is_method><complexity_score>7</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _parse_coverage_metrics(self, coverage_output: str) -&gt; Dict[str, str]:
        """Enhanced coverage metrics parsing"""
        metrics = {}
        if not coverage_output:
            return m...</code_snippet></function><function><name>_generate_json_report</name><file_path>ci_pr_test_runner.py</file_path><line_start>853</line_start><line_end>894</line_end><is_method>True</is_method><complexity_score>3</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _generate_json_report(self, report: TestReport) -&gt; str:
        """Enhanced JSON report generation"""
        
        # Convert test cases to dict explicitly
        test_cases_dict = [tc.to_...</code_snippet></function><function><name>_generate_xml_report</name><file_path>ci_pr_test_runner.py</file_path><line_start>896</line_start><line_end>968</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _generate_xml_report(self, report: TestReport) -&gt; str:
        """Enhanced XML report generation"""
        root = ET.Element("test_automation_report")
        
        # Header with additiona...</code_snippet></function><function><name>_generate_text_report</name><file_path>ci_pr_test_runner.py</file_path><line_start>970</line_start><line_end>1076</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _generate_text_report(self, report: TestReport) -&gt; str:
        """Enhanced human-readable text format report"""
        lines = [
            "🚀 Python Project Test Automation Report",
      ...</code_snippet></function><function><name>_save_reports</name><file_path>ci_pr_test_runner.py</file_path><line_start>1078</line_start><line_end>1102</line_end><is_method>True</is_method><complexity_score>1</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def _save_reports(self, report: TestReport):
        """Save enhanced reports in multiple formats"""
        timestamp_str = report.timestamp.replace(":", "-").replace(" ", "_")
        base_filen...</code_snippet></function><function><name>run</name><file_path>ci_pr_test_runner.py</file_path><line_start>1104</line_start><line_end>1281</line_end><is_method>True</is_method><complexity_score>10</complexity_score><class_name>ChangeAnalyzerAndTester</class_name><code_snippet>    def run(self):
        """Enhanced main runner with comprehensive validation"""
        self._log("🚀 Starting Enhanced Python Project Test Automation", "INFO")
        
        changed_files = sel...</code_snippet></function><function><name>sum_three_numbers</name><file_path>utils.py</file_path><line_start>1</line_start><line_end>13</line_end><is_method>False</is_method><complexity_score>1</complexity_score><code_snippet>def sum_three_numbers(a, b, c):
    """
    Calculates the sum of three numbers.

    Args:
        a (int or float): The first number.
        b (int or float): The second number.
        c (int or f...</code_snippet></function></analyzed_functions><test_results><status>failure</status><output>Failed to generate test cases</output></test_results><test_cases /><coverage_metrics /><execution_logs><count>19</count><log>[2025-09-14 06:13:47] [INFO] 🚀 Starting Enhanced Python Project Test Automation</log><log>[2025-09-14 06:13:47] [INFO] 📁 Detected 7 changed files: ci_pr_test_runner.py, reports/run_summary.txt, reports/test_automation_report_2025-09-14_05-40-18.json, reports/test_automation_report_2025-09-14_05-40-18.txt, reports/test_automation_report_2025-09-14_05-40-18.xml, tests_pr/pr_generated_tests.py, utils.py</log><log>[2025-09-14 06:13:47] [INFO] 🔍 Analyzing changed file: ci_pr_test_runner.py</log><log>[2025-09-14 06:13:47] [INFO] ✅ Found 26 functions/methods in ci_pr_test_runner.py</log><log>[2025-09-14 06:13:47] [INFO] 🔍 Analyzing changed file: utils.py</log><log>[2025-09-14 06:13:47] [INFO] ✅ Found 1 functions/methods in utils.py</log><log>[2025-09-14 06:13:47] [INFO] 📊 Analysis Summary:</log><log>[2025-09-14 06:13:47] [INFO]    Total Functions/Methods: 27</log><log>[2025-09-14 06:13:47] [INFO]    Functions: 1, Methods: 26</log><log>[2025-09-14 06:13:47] [INFO]    Average Complexity: 5.9/10</log><log>[2025-09-14 06:13:47] [INFO] 🧠 Generating comprehensive test cases using llama-3.3-70b-versatile...</log><log>[2025-09-14 06:13:47] [INFO] 🤖 Generating test code (attempt 1/3)...</log><log>[2025-09-14 06:13:48] [ERROR] ❌ Error in LLM generation (attempt 1): Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01k4vv26wrfy0a45edrkbynbm1` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Requested 15631, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}</log><log>[2025-09-14 06:13:48] [INFO] 🤖 Generating test code (attempt 2/3)...</log><log>[2025-09-14 06:13:48] [ERROR] ❌ Error in LLM generation (attempt 2): Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01k4vv26wrfy0a45edrkbynbm1` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Requested 15631, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}</log><log>[2025-09-14 06:13:48] [INFO] 🤖 Generating test code (attempt 3/3)...</log><log>[2025-09-14 06:13:48] [ERROR] ❌ Error in LLM generation (attempt 3): Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01k4vv26wrfy0a45edrkbynbm1` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Requested 15631, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}</log><log>[2025-09-14 06:13:48] [ERROR] ❌ Failed to generate test cases. Aborting.</log><log>[2025-09-14 06:13:48] [INFO] 📄 JSON report saved: /home/runner/work/check-python-tests/check-python-tests/reports/test_automation_report_2025-09-14_06-13-48.json</log></execution_logs></test_automation_report>